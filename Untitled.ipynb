{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import sklearn\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "iowa_filepath = 'train.csv'\n",
    "test_iowa_filepath = 'test.csv'\n",
    "train_iowa_data = pd.read_csv(iowa_filepath)\n",
    "test_iowa_data = pd.read_csv(test_iowa_filepath)\n",
    "train_iowa_data.info()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "train_iowa_data.hist(bins=50, figsize=(20,15))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = train_iowa_data.corr()\n",
    "correlations = corr_matrix[\"SalePrice\"].sort_values(ascending=False)\n",
    "features = correlations.index[1:6]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_null = pd.isnull(train_iowa_data).sum()\n",
    "testing_null = pd.isnull(test_iowa_data).sum()\n",
    "null = pd.concat([training_null, testing_null], axis=1, keys=[\"Training\", \"Testing\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_many = null[null.sum(axis=1) > 200]\n",
    "null_few = null[(null.sum(axis=1) > 0) & (null.sum(axis=1) < 200)] \n",
    "#null_many\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_has_meaning = [\"Alley\", \"BsmtQual\", \"BsmtCond\", \"BsmtExposure\", \"BsmtFinType1\", \"BsmtFinType2\", \"FireplaceQu\", \"GarageType\", \"GarageFinish\", \"GarageQual\", \"GarageCond\", \"PoolQC\", \"Fence\", \"MiscFeature\"]\n",
    "for i in null_has_meaning:\n",
    "    train_iowa_data[i].fillna(\"None\", inplace=True)\n",
    "    test_iowa_data[i].fillna(\"None\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_null = pd.isnull(train_iowa_data).sum()\n",
    "testing_null = pd.isnull(test_iowa_data).sum()\n",
    "\n",
    "null = pd.concat([training_null, testing_null], axis=1, keys=[\"Training\", \"Testing\"])\n",
    "null_many = null[null.sum(axis=1) > 200]  #a lot of missing values\n",
    "null_few = null[(null.sum(axis=1) > 0) & (null.sum(axis=1) < 200)]  #few missing values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iowa_data.drop(\"LotFrontage\", axis=1, inplace=True)\n",
    "test_iowa_data.drop(\"LotFrontage\", axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iowa_data[\"GarageYrBlt\"].fillna(train_iowa_data[\"GarageYrBlt\"].median(), inplace=True)\n",
    "test_iowa_data[\"GarageYrBlt\"].fillna(test_iowa_data[\"GarageYrBlt\"].median(), inplace=True)\n",
    "train_iowa_data[\"MasVnrArea\"].fillna(train_iowa_data[\"MasVnrArea\"].median(), inplace=True)\n",
    "test_iowa_data[\"MasVnrArea\"].fillna(test_iowa_data[\"MasVnrArea\"].median(), inplace=True)\n",
    "train_iowa_data[\"MasVnrType\"].fillna(\"None\", inplace=True)\n",
    "test_iowa_data[\"MasVnrType\"].fillna(\"None\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "types_train = train_iowa_data.dtypes\n",
    "cat_train = types_train[(types_train == object)] \n",
    "num_train = types_train[(types_train == int)]\n",
    "#print(cat_train)\n",
    "#we do the same for the test set\n",
    "types_test = test_iowa_data.dtypes\n",
    "num_test = types_test[(types_test == int) | (types_test == float)]\n",
    "cat_test = types_test[(types_test == object)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_values_train = list(num_train.index)\n",
    "numerical_values_test = list(num_test.index)\n",
    "numerical_values_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fill_num = []\n",
    "\n",
    "for i in numerical_values_train:\n",
    "    if i in list(null_few.index):\n",
    "        fill_num.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in fill_num:\n",
    "    train_iowa_data[i].fillna(train_iowa_data[i].median(), inplace=True)\n",
    "    test_iowa_data[i].fillna(test_iowa_data[i].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_values_train = list(cat_train.index)\n",
    "categorical_values_test = list(cat_test.index)\n",
    "fill_cat = []\n",
    "\n",
    "for i in categorical_values_train:\n",
    "    if i in list(null_few.index):\n",
    "        fill_cat.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_common_term(lst):\n",
    "    lst = list(lst)\n",
    "    return max(set(lst), key=lst.count)\n",
    "#most_common_term finds the most common term in a series\n",
    "\n",
    "most_common = [\"Electrical\", \"Exterior1st\", \"Exterior2nd\", \"Functional\", \"KitchenQual\", \"MSZoning\", \"SaleType\", \"Utilities\", \"MasVnrType\"]\n",
    "\n",
    "counter = 0\n",
    "for i in fill_cat:\n",
    "    most_common[counter] = most_common_term(training[i])\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_common_dictionary = {fill_cat[0]: [most_common[0]], fill_cat[1]: [most_common[1]], fill_cat[2]: [most_common[2]], fill_cat[3]: [most_common[3]],\n",
    "                          fill_cat[4]: [most_common[4]], fill_cat[5]: [most_common[5]], fill_cat[6]: [most_common[6]], fill_cat[7]: [most_common[7]],\n",
    "                          fill_cat[8]: [most_common[8]]}\n",
    "most_common_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "for i in fill_cat:  \n",
    "    training[i].fillna(most_common[counter], inplace=True)\n",
    "    testing[i].fillna(most_common[counter], inplace=True)\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_null = pd.isnull(train_iowa_data).sum()\n",
    "testing_null = pd.isnull(test_iowa_data).sum()\n",
    "\n",
    "null = pd.concat([training_null, testing_null], axis=1, keys=[\"Training\", \"Testing\"])\n",
    "null[null.sum(axis=1) > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iowa_data[\"TransformedPrice\"] = np.log(train_iowa_data[\"SalePrice\"])\n",
    "categorical_values_train = list(cat_train.index)\n",
    "categorical_values_test = list(cat_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in categorical_values_train:\n",
    "    feature_set = set(train_iowa_data[i])\n",
    "    for j in feature_set:\n",
    "        feature_list = list(feature_set)\n",
    "        train_iowa_data.loc[train_iowa_data[i] == j, i] = feature_list.index(j)\n",
    "\n",
    "for i in categorical_values_test:\n",
    "    feature_set2 = set(test_iowa_data[i])\n",
    "    for j in feature_set2:\n",
    "        feature_list2 = list(feature_set2)\n",
    "        test_iowa_data.loc[testing[i] == j, i] = feature_list2.index(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.cross_validation import cross_val_score, KFold\n",
    "X_train = train_iowa_data.drop([\"Id\", \"SalePrice\", \"TransformedPrice\"], axis=1).values\n",
    "y_train = train_iowa_data[\"TransformedPrice\"].values\n",
    "X_test = test_iowa_data.drop(\"Id\", axis=1).values\n",
    "from sklearn.model_selection import train_test_split #to create validation data set\n",
    "\n",
    "X_training, X_valid, y_training, y_valid = train_test_split(X_train, y_train, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor()\n",
    "paremeters_rf = {\"n_estimators\" : [5, 10, 15, 20], \"criterion\" : [\"mse\" , \"mae\"], \"min_samples_split\" : [2, 3, 5, 10], \n",
    "                 \"max_features\" : [\"auto\", \"log2\"]}\n",
    "grid_rf = GridSearchCV(rf, paremeters_rf, verbose=1, scoring=\"r2\")\n",
    "grid_rf.fit(X_training, y_training)\n",
    "\n",
    "print(\"Best RandomForestRegressor Model: \" + str(grid_rf.best_estimator_))\n",
    "print(\"Best Score: \" + str(grid_rf.best_score_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = grid_rf.best_estimator_\n",
    "rf.fit(X_training, y_training)\n",
    "rf_pred = rf.predict(X_valid)\n",
    "r2_rf = r2_score(y_valid, rf_pred)\n",
    "rmse_rf = np.sqrt(mean_squared_error(y_valid, rf_pred))\n",
    "print(\"R^2 Score: \" + str(r2_rf))\n",
    "print(\"RMSE Score: \" + str(rmse_rf))\n",
    "scores_rf = cross_val_score(rf, X_training, y_training, cv=10, scoring=\"r2\")\n",
    "print(\"Cross Validation Score: \" + str(np.mean(scores_rf)))\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_predictions = np.exp(rf.predict(X_test))\n",
    "submission = pd.DataFrame({\n",
    "        \"Id\": testing[\"Id\"],\n",
    "        \"SalePrice\": submission_predictions\n",
    "    })\n",
    "\n",
    "submission.to_csv(\"prices.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
